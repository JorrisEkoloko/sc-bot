# Dual-Metric Performance System - Implementation Analysis

## Executive Summary

Analysis of codebase to determine where dual-metric performance evaluation (ATH + Final) needs to be implemented for the recommended classification system.

**Date**: November 14, 2025  
**Status**: Ready for Spec Creation

---

## Recommended Classification System

### Performance Categories

| Category          | Criteria                    | Emoji | Description                     |
| ----------------- | --------------------------- | ----- | ------------------------------- |
| **MOON** üåô       | ATH ‚â• 5.0x                  | üåô    | Exceptional performance         |
| **WINNER** ‚úÖ     | ATH ‚â• 2.0x AND Final ‚â• 1.0x | ‚úÖ    | Profitable with sustained gains |
| **GOOD** üëç       | ATH ‚â• 1.5x AND Final ‚â• 0.9x | üëç    | Decent performance              |
| **BREAK-EVEN** ‚öñÔ∏è | ATH ‚â• 1.0x AND Final ‚â• 0.9x | ‚öñÔ∏è    | No significant loss             |
| **LOSER** ‚ùå      | Final < 0.9x                | ‚ùå    | Lost money                      |
| **CRASH** üí•      | Final < 0.5x                | üí•    | Major loss/rug pull             |

### Key Insights

- **ATH captures opportunity**: Shows peak potential (for traders who took profit)
- **Final captures reality**: Shows actual outcome (for holders)
- **Gap identifies risk**: Large ATH-Final gap = pump & dump pattern
- **Fair to channels**: Rewards both peak opportunity AND sustainable performance

---

## Current System Analysis

### 1. Performance Tracking (`services/tracking/performance_tracker.py`)

**Current Implementation**:

```python
# Tracks ATH since mention
'ath_since_mention': initial_price,
'ath_time': now.isoformat(),
'current_price': initial_price,
'last_update': now.isoformat()
```

**What's Missing**:

- ‚ùå No final price capture at 7-day completion
- ‚ùå No dual-metric classification
- ‚ùå No performance gap calculation
- ‚ùå No category assignment (MOON/WINNER/etc.)

**What's Good**:

- ‚úÖ Already tracks ATH price and time
- ‚úÖ Already tracks current price
- ‚úÖ Already calculates ATH multiplier
- ‚úÖ Already has 7-day tracking window

---

### 2. ROI Calculator (`utils/roi_calculator.py`)

**Current Implementation**:

```python
@staticmethod
def categorize_outcome(ath_multiplier: float) -> Tuple[bool, str]:
    """Single-metric categorization based on ATH only"""
    if ath_multiplier >= 5.0:
        category = "moon"
    elif ath_multiplier >= 3.0:
        category = "great"
    # ... etc
```

**What's Missing**:

- ‚ùå No final price consideration
- ‚ùå No dual-metric logic (ATH + Final)
- ‚ùå No crash detection (Final < 0.5x)
- ‚ùå No performance gap calculation

**What's Good**:

- ‚úÖ Already has categorization framework
- ‚úÖ Already calculates ROI multipliers
- ‚úÖ Already has is_winner logic

---

### 3. Signal Outcome (`domain/signal_outcome.py`)

**Current Implementation**:

```python
@dataclass
class SignalOutcome:
    # Outcome data (ATH = All-Time High)
    ath_price: float = 0.0
    ath_multiplier: float = 0.0
    current_price: float = 0.0
    current_multiplier: float = 0.0

    # Status
    is_winner: bool = False
    outcome_category: str = ""  # moon, great, good, moderate, break_even, loss
```

**What's Missing**:

- ‚ùå No final_price field (distinct from current_price)
- ‚ùå No final_multiplier field
- ‚ùå No performance_gap field
- ‚ùå No dual-metric category

**What's Good**:

- ‚úÖ Already has ATH fields
- ‚úÖ Already has outcome_category field
- ‚úÖ Already has is_winner field
- ‚úÖ Already has checkpoints system

---

### 4. Reputation Calculator (`services/reputation/reputation_calculator.py`)

**Current Implementation**:

```python
@staticmethod
def calculate_win_rate(outcomes: List[SignalOutcome]) -> tuple:
    """Uses is_winner field (market-tier aware)"""
    winners = sum(1 for o in outcomes if o.is_winner)
```

**What's Missing**:

- ‚ùå No dual-metric win rate calculation
- ‚ùå No crash rate tracking
- ‚ùå No performance gap analysis
- ‚ùå No category distribution metrics

**What's Good**:

- ‚úÖ Already processes outcomes list
- ‚úÖ Already calculates win rates
- ‚úÖ Already has tier-specific logic
- ‚úÖ Already calculates composite scores

---

## Implementation Requirements

### Phase 1: Data Model Updates

**File**: `domain/signal_outcome.py`

**Add Fields**:

```python
@dataclass
class SignalOutcome:
    # ... existing fields ...

    # Dual-metric performance (NEW)
    final_price: float = 0.0  # Price at 7-day completion
    final_multiplier: float = 0.0  # Final ROI multiplier
    performance_gap: float = 0.0  # ATH - Final (drawdown from peak)

    # Enhanced categorization (UPDATED)
    outcome_category: str = ""  # MOON, WINNER, GOOD, BREAK-EVEN, LOSER, CRASH
    category_emoji: str = ""  # üåô, ‚úÖ, üëç, ‚öñÔ∏è, ‚ùå, üí•
```

---

### Phase 2: ROI Calculator Updates

**File**: `utils/roi_calculator.py`

**Replace Method**:

```python
@staticmethod
def categorize_outcome_dual_metric(
    ath_multiplier: float,
    final_multiplier: float
) -> Tuple[bool, str, str, float]:
    """
    Dual-metric categorization (ATH + Final).

    Returns:
        Tuple[bool, str, str, float]: (is_winner, category, emoji, gap)
    """
    gap = ath_multiplier - final_multiplier

    # CRASH: Major loss (rug pull pattern)
    if final_multiplier < 0.5:
        return (False, "CRASH", "üí•", gap)

    # LOSER: Lost money
    if final_multiplier < 0.9:
        return (False, "LOSER", "‚ùå", gap)

    # MOON: Exceptional performance
    if ath_multiplier >= 5.0:
        return (True, "MOON", "üåô", gap)

    # WINNER: Profitable with sustained gains
    if ath_multiplier >= 2.0 and final_multiplier >= 1.0:
        return (True, "WINNER", "‚úÖ", gap)

    # GOOD: Decent performance
    if ath_multiplier >= 1.5 and final_multiplier >= 0.9:
        return (True, "GOOD", "üëç", gap)

    # BREAK-EVEN: No significant loss
    if ath_multiplier >= 1.0 and final_multiplier >= 0.9:
        return (False, "BREAK-EVEN", "‚öñÔ∏è", gap)

    # Default to LOSER
    return (False, "LOSER", "‚ùå", gap)
```

---

### Phase 3: Performance Tracker Updates

**File**: `services/tracking/performance_tracker.py`

**Add Method**:

```python
async def complete_tracking(self, address: str, final_price: float) -> dict:
    """
    Complete 7-day tracking and calculate final metrics.

    Args:
        address: Token contract address
        final_price: Final price at 7-day completion

    Returns:
        dict: Complete performance metrics with dual-metric classification
    """
    if address not in self.tracking_data:
        return None

    entry = self.tracking_data[address]

    # Calculate final metrics
    final_multiplier = final_price / entry['start_price']
    ath_multiplier = entry['ath_since_mention'] / entry['start_price']
    performance_gap = ath_multiplier - final_multiplier

    # Dual-metric categorization
    is_winner, category, emoji, gap = ROICalculator.categorize_outcome_dual_metric(
        ath_multiplier, final_multiplier
    )

    return {
        'address': address,
        'start_price': entry['start_price'],
        'ath_price': entry['ath_since_mention'],
        'final_price': final_price,
        'ath_multiplier': ath_multiplier,
        'final_multiplier': final_multiplier,
        'performance_gap': performance_gap,
        'is_winner': is_winner,
        'category': category,
        'emoji': emoji,
        'days_tracked': (datetime.now() - datetime.fromisoformat(entry['start_time'])).days
    }
```

---

### Phase 4: Outcome Tracker Updates

**File**: `services/tracking/outcome_tracker.py`

**Update Completion Logic**:

```python
async def complete_signal(self, outcome: SignalOutcome, final_price: float):
    """
    Complete signal tracking with dual-metric classification.

    Args:
        outcome: Signal outcome to complete
        final_price: Final price at completion
    """
    # Calculate final metrics
    outcome.final_price = final_price
    _, outcome.final_multiplier = ROICalculator.calculate_roi(
        outcome.entry_price, final_price
    )

    # Calculate performance gap
    outcome.performance_gap = outcome.ath_multiplier - outcome.final_multiplier

    # Dual-metric categorization
    is_winner, category, emoji, gap = ROICalculator.categorize_outcome_dual_metric(
        outcome.ath_multiplier, outcome.final_multiplier
    )

    outcome.is_winner = is_winner
    outcome.outcome_category = category
    outcome.category_emoji = emoji

    # Mark as complete
    outcome.is_complete = True
    outcome.status = "completed"

    # Save to repository
    await self.repository.save_outcome(outcome)
```

---

### Phase 5: Reputation Calculator Updates

**File**: `services/reputation/reputation_calculator.py`

**Add Methods**:

```python
@staticmethod
def calculate_category_distribution(outcomes: List[SignalOutcome]) -> dict:
    """
    Calculate distribution of outcome categories.

    Returns:
        dict: Count and percentage for each category
    """
    if not outcomes:
        return {}

    categories = {}
    for outcome in outcomes:
        cat = outcome.outcome_category
        categories[cat] = categories.get(cat, 0) + 1

    total = len(outcomes)
    return {
        cat: {
            'count': count,
            'percentage': (count / total) * 100
        }
        for cat, count in categories.items()
    }

@staticmethod
def calculate_crash_rate(outcomes: List[SignalOutcome]) -> tuple[int, float]:
    """
    Calculate crash rate (Final < 0.5x).

    Returns:
        tuple[int, float]: (crash_count, crash_rate_percentage)
    """
    if not outcomes:
        return (0, 0.0)

    crashes = sum(1 for o in outcomes if o.outcome_category == "CRASH")
    crash_rate = (crashes / len(outcomes)) * 100

    return (crashes, crash_rate)

@staticmethod
def calculate_average_gap(outcomes: List[SignalOutcome]) -> tuple[float, float, float]:
    """
    Calculate performance gap statistics (ATH - Final).

    Returns:
        tuple[float, float, float]: (avg_gap, max_gap, median_gap)
    """
    if not outcomes:
        return (0.0, 0.0, 0.0)

    gaps = [o.performance_gap for o in outcomes if hasattr(o, 'performance_gap')]

    if not gaps:
        return (0.0, 0.0, 0.0)

    avg_gap = statistics.mean(gaps)
    max_gap = max(gaps)
    median_gap = statistics.median(gaps)

    return (avg_gap, max_gap, median_gap)
```

---

### Phase 6: CSV Output Updates

**File**: `repositories/writers/csv_writer.py`

**Update Performance Table Columns**:

```python
PERFORMANCE_COLUMNS = [
    'address', 'chain', 'first_message_id',
    'start_price', 'start_time',
    'ath_price', 'ath_time', 'ath_multiplier',
    'final_price', 'final_multiplier',  # NEW
    'performance_gap',  # NEW
    'category', 'emoji',  # NEW
    'days_tracked'
]
```

---

## Integration Points

### 1. Message Processing Flow

```
Message Received
    ‚Üì
Address Extracted
    ‚Üì
Performance Tracker: start_tracking()
    ‚Üì
[7 days of price updates]
    ‚Üì
Performance Tracker: complete_tracking()  ‚Üê DUAL-METRIC CLASSIFICATION
    ‚Üì
Outcome Tracker: complete_signal()  ‚Üê SAVE WITH CATEGORY
    ‚Üì
Reputation Engine: update_reputation()  ‚Üê USE NEW METRICS
```

### 2. Data Flow

```
PerformanceTracker
    ‚îú‚îÄ Tracks: ATH price, current price
    ‚îú‚îÄ Calculates: ATH multiplier
    ‚îî‚îÄ On completion: final_price, final_multiplier, gap
        ‚Üì
ROICalculator
    ‚îú‚îÄ Input: ath_multiplier, final_multiplier
    ‚îî‚îÄ Output: category, emoji, is_winner, gap
        ‚Üì
SignalOutcome
    ‚îú‚îÄ Stores: All metrics
    ‚îî‚îÄ Persists: To JSON repository
        ‚Üì
ReputationCalculator
    ‚îú‚îÄ Analyzes: Category distribution
    ‚îú‚îÄ Calculates: Crash rate, gap statistics
    ‚îî‚îÄ Updates: Channel reputation scores
```

---

## Testing Requirements

### Unit Tests

1. **ROI Calculator Tests**

   - Test all 6 categories (MOON, WINNER, GOOD, BREAK-EVEN, LOSER, CRASH)
   - Test edge cases (ATH = Final, Final > ATH)
   - Test gap calculation accuracy

2. **Performance Tracker Tests**

   - Test completion with various price scenarios
   - Test dual-metric calculation
   - Test category assignment

3. **Reputation Calculator Tests**
   - Test category distribution calculation
   - Test crash rate calculation
   - Test gap statistics

### Integration Tests

1. **End-to-End Flow**

   - Track signal from start to completion
   - Verify dual-metric classification
   - Verify reputation update

2. **Real Data Validation**
   - Test with TRUMP example (ATH 5.0x, Final 0.03x = CRASH)
   - Test with successful signal (ATH 3.0x, Final 2.5x = WINNER)
   - Test with pump & dump (ATH 10x, Final 0.8x = LOSER)

---

## Migration Strategy

### Backward Compatibility

**Existing Data**:

- Current `signal_outcomes.json` has ATH data
- Missing: final_price, final_multiplier, performance_gap
- Solution: Add migration script to populate missing fields

**Migration Script**:

```python
def migrate_existing_outcomes():
    """Add dual-metric fields to existing outcomes."""
    for outcome in existing_outcomes:
        if not hasattr(outcome, 'final_price'):
            # Use current_price as final_price for completed signals
            outcome.final_price = outcome.current_price
            outcome.final_multiplier = outcome.current_multiplier
            outcome.performance_gap = outcome.ath_multiplier - outcome.final_multiplier

            # Recalculate category with dual-metric
            is_winner, category, emoji, gap = ROICalculator.categorize_outcome_dual_metric(
                outcome.ath_multiplier, outcome.final_multiplier
            )
            outcome.outcome_category = category
            outcome.category_emoji = emoji
```

---

## Performance Impact

### Computational Cost

- **Minimal**: Only adds 3 calculations per signal completion
  - final_multiplier = final_price / entry_price
  - performance_gap = ath_multiplier - final_multiplier
  - category = categorize_outcome_dual_metric()

### Storage Cost

- **Minimal**: Adds 4 fields per signal outcome
  - final_price (float): 8 bytes
  - final_multiplier (float): 8 bytes
  - performance_gap (float): 8 bytes
  - category_emoji (str): ~4 bytes
  - **Total**: ~28 bytes per signal

### API Impact

- **None**: No additional API calls required
- Uses existing price data from tracking

---

## Success Metrics

### Implementation Success

- ‚úÖ All 6 categories correctly assigned
- ‚úÖ Performance gap accurately calculated
- ‚úÖ Backward compatibility maintained
- ‚úÖ CSV output includes new columns
- ‚úÖ Reputation metrics use dual-metric logic

### Business Success

- ‚úÖ Identifies pump & dump patterns (large gap)
- ‚úÖ Rewards sustainable performance (WINNER vs LOSER)
- ‚úÖ Fair channel reputation scoring
- ‚úÖ Clear signal quality classification

---

## Files to Modify

### Core Changes (Required)

1. ‚úÖ `domain/signal_outcome.py` - Add dual-metric fields
2. ‚úÖ `utils/roi_calculator.py` - Update categorization logic
3. ‚úÖ `services/tracking/performance_tracker.py` - Add completion method
4. ‚úÖ `services/tracking/outcome_tracker.py` - Update completion logic
5. ‚úÖ `services/reputation/reputation_calculator.py` - Add new metrics

### Supporting Changes (Optional)

6. ‚ö†Ô∏è `repositories/writers/csv_writer.py` - Update columns
7. ‚ö†Ô∏è `infrastructure/output/data_output.py` - Update output format
8. ‚ö†Ô∏è `scripts/migrate_outcomes.py` - Create migration script

### Documentation Updates

9. üìù Update implementation guides
10. üìù Update API documentation
11. üìù Update user guides

---

## Next Steps

1. **Create Spec**: Formal specification document
2. **Review & Approve**: Stakeholder review
3. **Implementation**: Phase-by-phase development
4. **Testing**: Unit + integration tests
5. **Migration**: Update existing data
6. **Deployment**: Production rollout
7. **Monitoring**: Track new metrics

---

## Conclusion

The dual-metric performance evaluation system is:

- ‚úÖ **Validated**: Industry-standard approach
- ‚úÖ **Feasible**: Minimal code changes required
- ‚úÖ **Valuable**: Better signal quality assessment
- ‚úÖ **Ready**: Clear implementation path

**Recommendation**: PROCEED WITH SPEC CREATION

---

**Document Version**: 1.0  
**Last Updated**: November 14, 2025  
**Status**: ‚úÖ READY FOR SPEC
